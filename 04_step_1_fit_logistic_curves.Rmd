---
title: "04 Step 1: Fit logistic curves"
author: "Miranda Gómez Díaz"
date: "2023-02-22"
output: html_document
---
```{r}
#Read needed packages
library(drc)
library(tidyverse)
library(RColorBrewer)
library(tibble)
library(gridExtra)
library(ggpubr)
```

```{r}
# Read files from previous steps
vocabulary_scores_03_df <- read_csv("data/03_vocabulary_scores.csv") 

LEQ_01_df <- read_csv("data/01_LEQ_columns.csv")
```

```{r}
# Clean and wrangle df for Step 1

# Keep necessary columns
step1_df <- vocabulary_scores_03_df %>%
  arrange(item_id_eng) %>%
  # Remove participants who were older than 18 months when they joined the study
  filter(!(starting_age > 18)) %>% #HK note: just wanted to flag this because it's keeping anyone who is exactly 18 months old, but not someone who is 18.1 months old. Is that what you want?
  # Remove duplicated rows (keep 1 row per baby per month) 
  group_by(study_id, n_months) %>%
  summarize(age = first(age), 
            starting_age = first(starting_age), 
            eng_completed = first(eng_completed),
            fr_completed = first(fr_completed),
            eng_est_total_produced = first(eng_est_total_produced), 
            fr_est_total_produced = first(fr_est_total_produced), 
            words_produced = first(words_produced),
            concepts_produced = first(concepts_produced),
            num_datapts = first(num_datapts)) %>%
  # Create vocabulary_score column (includes scores for English, French, word, and concept vocabulary scores) and vocabulary_type_step1 column
  rename('English' = 'eng_est_total_produced',
         'French' = 'fr_est_total_produced',
         'word' = 'words_produced',
         'concept' = 'concepts_produced') %>%
  pivot_longer(-c(study_id:fr_completed, num_datapts), names_to = "vocabulary_type_step1", values_to = "vocabulary_score") %>%
  # Remove rows of monolinguals' non-heard language
  ungroup() %>%
  filter(!(vocabulary_type_step1 == 'English' & is.na(eng_completed))) %>%
  filter(!(vocabulary_type_step1 == 'French' & is.na(fr_completed))) %>% 
  # Estimate number of data points missing by baby in each vocabulary type
  group_by(study_id, vocabulary_type_step1) %>% 
  mutate(num_missing_datapts = sum(is.na(vocabulary_score)),
         # Set the maximum vocabulary size for single languages(i.e., the max CDI score in English and/or French)
         total = case_when(vocabulary_type_step1 == 'English' ~ 680,
                           vocabulary_type_step1 == 'French' ~ 664)) %>% 
  ungroup() %>% 
  group_by(study_id, n_months) %>% 
  # Set the maximum vocabulary size for combined languages
  mutate(total = case_when(vocabulary_type_step1 == 'word' ~ sum(total, na.rm = TRUE),
                           vocabulary_type_step1 == 'concept' ~ sum(total, na.rm = TRUE),
                           TRUE ~ total)) %>% 
  mutate(total = case_when(vocabulary_type_step1 == 'concept' & total == 1344 ~ 1344 - 611,
                           TRUE ~ total)) %>% #HK note: Adding an ungroup() here just so the dataframe doesn't behave weirdly in the future
  ungroup()

# Create df with babies who were older then 18 months when they started study 
startage_over18 <- vocabulary_scores_03_df %>%
  filter(starting_age > 18) %>%
  distinct(study_id)

```

```{r}
# Determine language status of keepers
lang_status_df <- step1_df %>% 
  # Join coefficients and language exposure dataframes
  # Use left_join because LEQ dataset has full sample (N=125), as babies were not excluded from it
  left_join(LEQ_01_df, by = "study_id") %>% 
  group_by(study_id) %>% 
  summarize(lang_status = first(lang_status),
            cumulative_exp_Eng = first(cumulative_exp_Eng),
            cumulative_exp_Fre = first(cumulative_exp_Fre),
            cumulative_exp_L3 = first(cumulative_exp_L3),
            cumulative_exp_L4 = first(cumulative_exp_L4),
            starting_age = first(starting_age)) %>% 
  # Set exposure balance as the exposure to the non-dominant language (lower cumulative exposure)
  mutate(exposure_balance = case_when(
    cumulative_exp_Eng < cumulative_exp_Fre ~ cumulative_exp_Eng,
    cumulative_exp_Fre < cumulative_exp_Eng ~ cumulative_exp_Fre))
```

```{r}
# Fit logistic curve to individual data (single-language, word, and concept vocabularies): LL.3 (lower limit fixed at 0), continuous type of data. This data framme is used for following analyses.
# THIS APPROACH ALLOWS FOR CURVE-FITTING AND CHECKING MODEL FIT

# Clean and prepare dataframe
logistic_curve <- step1_df %>%
  filter(!(eng_completed == FALSE & vocabulary_type_step1 == "English")) %>%
  filter(!(fr_completed == FALSE & vocabulary_type_step1 == "French")) %>%
  unite(id_lang, c(study_id, vocabulary_type_step1)) 

# Create empty dataframes to fill with results from each baby in each vocabulary type
logistic_curve_coefficients_LL3_conti <- setNames(data.frame(matrix(ncol = 4, nrow = 0)), c("id_lang", "midpoint", "slope", "upper_limit"))
model_AICs_LL3_conti <- setNames(data.frame(matrix(ncol = 5, nrow = 0)), c("id_lang","AIC_LL.3", "AIC_Cubic", "AIC_Quad", "AIC_Lin")) 


  for(i in unique(logistic_curve$id_lang)) {
    unique_id_voc <- logistic_curve %>% filter(id_lang == i)
    individual_curve <- drm(vocabulary_score~age, # For continuous type
                            data = unique_id_voc,
                 fct=LL.3(names = c("Slope", "Upper Limit", "Midpoint")),
                 type = "continuous" # For continuous type
                 )
    # list.append(logistic_curve_coefficients, individual_curve)
    # print(i)
    # print(individual_curve)
    # Model fit dataframe
    individual_model_fit <- as.data.frame(mselect(individual_curve, linreg = TRUE, icfct = AIC)) %>% 
      dplyr::select(IC) %>% 
      rownames_to_column("names") %>% 
      pivot_wider(names_from = names, names_prefix = "AIC_", values_from =IC) %>% 
      mutate(id_lang = i) %>% 
      dplyr::select(id_lang, AIC_LL.3, AIC_Cubic, AIC_Quad, AIC_Lin) 
    
    model_AICs_LL3_conti[nrow(model_AICs_LL3_conti) + 1,] <- individual_model_fit[1:5]
    
    # print(individual_model_fit)
    individual_midpoint <- pluck(individual_curve,28,"Midpoint:(Intercept)")
    individual_slope <- pluck(individual_curve,28,"Slope:(Intercept)")
    individual_upper_limit <- pluck(individual_curve,28,"Upper Limit:(Intercept)")
    
    plot(individual_curve, main = i, sub = paste0("midpoint = ", as.character(individual_midpoint)))

    logistic_curve_coefficients_LL3_conti[nrow(logistic_curve_coefficients_LL3_conti) + 1,] <- list(i, individual_midpoint, individual_slope, individual_upper_limit)
  }

# Clean coefficients dataframe
coefficients_df <-  full_join(logistic_curve_coefficients_LL3_conti, model_AICs_LL3_conti, by = "id_lang") %>%
  separate(id_lang, c("study_id", "vocabulary_type_step1")) %>%
  # Convert slope values to positive
  mutate(slope = abs(slope))
```

```{r}
# Fit logistic curve to individual data (single-language, word, and concept vocabularies): LL.3 & LL.4, continuous

# Clean and prepare dataframe
logistic_curve <- step1_df %>%
  filter(!(eng_completed == FALSE & vocabulary_type_step1 == "English")) %>%
  filter(!(fr_completed == FALSE & vocabulary_type_step1 == "French")) %>%
  unite(id_lang, c(study_id, vocabulary_type_step1)) 

# Create empty dataframes to fill with results from each baby in each vocabulary type
logistic_curve_coefficients_conti <- setNames(data.frame(matrix(ncol = 8, nrow = 0)), c("id_lang", 
                                                                                            "LL3_midpoint", "LL3_slope", "LL3_upper_limit", 
                                                                                            "LL4_midpoint", "LL4_slope", "LL4_lower_limit", "LL4_upper_limit"))
model_AICs_conti <- setNames(data.frame(matrix(ncol = 6, nrow = 0)), c("id_lang","AIC_LL.3", "AIC_LL.4", "AIC_Cubic", "AIC_Quad", "AIC_Lin")) 


  for(i in unique(logistic_curve$id_lang)) {
    unique_id_voc <- logistic_curve %>% filter(id_lang == i)
    individual_LL3_curve <- drm(vocabulary_score~age, # For continuous type
                            # vocabulary_score/total~age, # For binomial type
                            # weights = total, # For binomial type
                            data = unique_id_voc,
                 fct=LL.3(names = c("Slope", "Upper Limit", "Midpoint")),
                 type = "continuous" # For continuous type
                 # type = "binomial" # For binomial type
                 )
    individual_LL4_curve <- drm(vocabulary_score~age, # For continuous type
                            # vocabulary_score/total~age, # For binomial type
                            # weights = total, # For binomial type
                            data = unique_id_voc,
                 fct=LL.4(names = c("Slope", "Lower Limit", "Upper Limit", "Midpoint")),
                 type = "continuous" # For continuous type
                 # type = "binomial" # For binomial type
                 )
    # list.append(logistic_curve_coefficients, individual_curve)
    # print(i)
    # print(individual_curve)
    # Model fit dataframe
    individual_model_fit <- as.data.frame(mselect(individual_LL3_curve, list(LL.4()), linreg = TRUE, icfct = AIC)) %>% 
      dplyr::select(IC) %>% 
      rownames_to_column("names") %>% 
      pivot_wider(names_from = names, names_prefix = "AIC_", values_from =IC) %>% 
      mutate(id_lang = i) %>% 
      dplyr::select(id_lang, AIC_LL.3, AIC_LL.4, AIC_Cubic, AIC_Quad, AIC_Lin) 
    
    model_AICs_conti[nrow(model_AICs_conti) + 1,] <- individual_model_fit[1:6]
    
    # print(individual_model_fit)
    individual_LL3_midpoint <- pluck(individual_LL3_curve,28,"Midpoint:(Intercept)")
    individual_LL3_slope <- pluck(individual_LL3_curve,28,"Slope:(Intercept)")
    individual_LL3_upper_limit <- pluck(individual_LL3_curve,28,"Upper Limit:(Intercept)")
    individual_LL4_midpoint <- pluck(individual_LL4_curve,28,"Midpoint:(Intercept)")
    individual_LL4_slope <- pluck(individual_LL4_curve,28,"Slope:(Intercept)")
    individual_LL4_lower_limit <- pluck(individual_LL4_curve,28,"Lower Limit:(Intercept)")
    individual_LL4_upper_limit <- pluck(individual_LL4_curve,28,"Upper Limit:(Intercept)")
    
    # plot(individual_curve, main = i, sub = paste0("midpoint = ", as.character(individual_midpoint)))

    logistic_curve_coefficients_conti[nrow(logistic_curve_coefficients_conti) + 1,] <- list(i, individual_LL3_midpoint, individual_LL3_slope,individual_LL3_upper_limit, individual_LL4_midpoint, individual_LL4_slope, individual_LL4_lower_limit, individual_LL4_upper_limit)
  }


# Clean coefficients dataframe
coefficients_df_conti <-  full_join(logistic_curve_coefficients_conti, model_AICs_conti, by = "id_lang") %>%
  separate(id_lang, c("study_id", "vocabulary_type_step1")) %>%
  # Convert slope values to positive
  mutate(LL3_slope = abs(LL3_slope),
         LL4_slope = abs(LL4_slope))
```

```{r}
# Fit logistic curve to individual data (single-language, word, and concept vocabularies): LL.3 & LL.4, binomial data

# Create empty dataframes to fill with results from each baby in each vocabulary type
logistic_curve_coefficients_binom <- setNames(data.frame(matrix(ncol = 8, nrow = 0)), c("id_lang", 
                                                                                            "LL3_midpoint", "LL3_slope", "LL3_upper_limit", 
                                                                                            "LL4_midpoint", "LL4_slope", "LL4_lower_limit", "LL4_upper_limit"))
model_AICs_binom <- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("id_lang","AIC_LL.3", "AIC_LL.4"
                                                                           # , "AIC_Cubic", "AIC_Quad", "AIC_Lin"
                                                                           )) 


  for(i in unique(logistic_curve$id_lang)) {
    unique_id_voc <- logistic_curve %>% filter(id_lang == i)
    individual_LL3_curve <- drm(vocabulary_score/total~age, # For binomial type
                            weights = total, # For binomial type
                            data = unique_id_voc,
                 fct=LL.3(names = c("Slope", "Upper Limit", "Midpoint")),
                 type = "binomial" # For binomial type
                 )
    individual_LL4_curve <- drm(vocabulary_score/total~age, # For binomial type
                            weights = total, # For binomial type
                            data = unique_id_voc,
                 fct=LL.4(names = c("Slope", "Lower Limit", "Upper Limit", "Midpoint")),
                 type = "binomial" # For binomial type
                 )
    # list.append(logistic_curve_coefficients, individual_curve)
    # print(i)
    # print(individual_curve)
    # Model fit dataframe
    individual_model_fit <- as.data.frame(mselect(individual_LL3_curve, list(LL.4()), linreg = FALSE, icfct = AIC)) %>% 
      rownames_to_column("names") %>%
      dplyr::select(names, IC) %>%
      # filter(names == "IC") #%>%
      mutate(id_lang = i) %>%
      pivot_wider(names_from = names, names_prefix = "AIC_", values_from =IC) #%>%
      # mutate(id_lang = i) %>%
      # select(id_lang, AIC_LL.3
      #        # , AIC_Cubic, AIC_Quad, AIC_Lin
      # )
    # print(individual_model_fit)
    
    model_AICs_binom[nrow(model_AICs_binom) + 1,] <- individual_model_fit[1:3]
    
    # print(individual_model_fit)
    individual_LL3_midpoint <- pluck(individual_LL3_curve,28,"Midpoint:(Intercept)")
    individual_LL3_slope <- pluck(individual_LL3_curve,28,"Slope:(Intercept)")
    individual_LL3_upper_limit <- pluck(individual_LL3_curve,28,"Upper Limit:(Intercept)")
    individual_LL4_midpoint <- pluck(individual_LL4_curve,28,"Midpoint:(Intercept)")
    individual_LL4_slope <- pluck(individual_LL4_curve,28,"Slope:(Intercept)")
    individual_LL4_lower_limit <- pluck(individual_LL4_curve,28,"Lower Limit:(Intercept)")
    individual_LL4_upper_limit <- pluck(individual_LL4_curve,28,"Upper Limit:(Intercept)")
    
    # plot(individual_LL3_curve, main = i, sub = paste0("midpoint = ", as.character(individual_midpoint)))

    logistic_curve_coefficients_binom[nrow(logistic_curve_coefficients_binom) + 1,] <- list(i, individual_LL3_midpoint, individual_LL3_slope,individual_LL3_upper_limit, individual_LL4_midpoint, individual_LL4_slope, individual_LL4_lower_limit, individual_LL4_upper_limit)
  }

# Clean coefficients dataframe
coefficients_df_binom <-  full_join(logistic_curve_coefficients_binom, model_AICs_binom, by = "id_lang") %>%
  separate(id_lang, c("study_id", "vocabulary_type_step1")) %>%
  # Convert slope values to positive
  mutate(LL3_slope = abs(LL3_slope),
         LL4_slope = abs(LL4_slope))
```

```{r}
# Join continuous and binomial dataframes
four_logistic_models_df <- full_join(coefficients_df_conti, coefficients_df_binom, by = c("study_id", "vocabulary_type_step1"), suffix = c("_conti", "_binom")) %>% 
  dplyr::select(study_id, vocabulary_type_step1, contains("midpoint"), contains("slope"), contains("lower_limit"), contains("upper_limit"), contains("AIC_LL.3"), contains("AIC_LL.4"), contains("Cubic"), contains("Quad"), contains("Lin"))

# Model fit table
model_fit_table <- four_logistic_models_df %>% 
  dplyr::select(study_id, vocabulary_type_step1, AIC_LL.3_conti:AIC_LL.4_binom) %>% 
  pivot_longer(!c(study_id, vocabulary_type_step1), names_to = "model", values_to = "AIC") %>% 
  group_by(study_id, vocabulary_type_step1) %>% 
  # Remove -Inf values
  filter(AIC > 0) %>% 
  # Remove LL4 values
  filter(model == "AIC_LL.3_conti" | model == "AIC_LL.3_binom") %>% 
  mutate(best_fit_model = case_when(AIC == min(AIC) ~ model)) %>% 
  filter(!is.na(best_fit_model)) %>% 
  ungroup() %>% 
  group_by(vocabulary_type_step1, model) %>% 
  summarise(N = n()) %>% 
  pivot_wider(names_from = model, values_from = N)
```

```{r}
# Sample descriptives
sample_descriptives <- step1_df %>% 
# Keep only one row per infant
  group_by(study_id) %>%
  filter(age == last(age),
         vocabulary_type_step1 == last(vocabulary_type_step1)) %>%
  ungroup() %>%
  # Join with LEQ data
  full_join(lang_status_df, by = c("study_id", "starting_age")) %>% 
  summarise(mean_startage = mean(starting_age),
            min_startage = min(starting_age),
            max_startage = max(starting_age),
            sd_startage = sd(starting_age),
            mean_datapts = mean(num_datapts),
            min_datapts = min(num_datapts),
            max_datapts = max(num_datapts),
            sd_datapts = sd(num_datapts),
            mean_expbal = mean(exposure_balance),
            min_expbal = min(exposure_balance),
            max_expbal = max(exposure_balance),
            sd_expbal = sd(exposure_balance))
```

```{r}
# Save dataframe as csv file
write_csv(step1_df, 'data/04_analysis_step_1_dataset.csv')
write_csv(coefficients_df, 'data/04_analysis_step_1_coefficients.csv')
```


