---
title: "LEQ check double entry discrepancies"
author: "Miranda Gómez Díaz"
date: "2023-04-26"
output: html_document
---

```{r}
# Read needed packages
library(tidyverse)
library(tidylog)
```

```{r}
# Read files (file names are saved with the date by default, remove the date from the name before reading file)
LEQ_discrepancies <- read_csv("data/discrepancies_to_check.csv")
LEQ_wide_double_data <- read_csv("data/wide_detailed_leq.csv")
```

```{r}
# On the csv file in Excel:
# Write down the correct response for each variable.

# Criteria to be considered when choosing a response:
# Date of participation: when LEQ was filled in paper
# What variety of ___ do you use?: Capitalize first letter (e.g. Canadian, British).
# What variety of ___ do you use?: Only demonym (e.g. keep Canadian, not Canadian French; Quebecois not Quebec)
# Caregiver’s 3 relationship to child: do not capitalize (e.g. grandmother).
# Caregiver’s 3 relationship to child: choose formal response (e.g. grandmother instead of grandma)
# Child age: check that it is correct based on date of birth (see recruitment log) and date when LEQ was filled in paper.
# No hours of a certain language in a day: pick 0 instead of NA.
# researcher_notes: do not include comment of "withdrew"
# When both parents are at home due to COVID: use "At home with primary caregiver 1 & 2"

# S114 has only one entry (possibly due to a glitch). It was checked manually and the data is correct, except for the global estimate (parents estimated 99% French, 1% English, but 100% French and 0% English was entered in Qualtrics)

```

```{r}
# Convert discrepancies dataframe to wide

LEQ_wide_discrepancies <- LEQ_discrepancies %>% 
  select(study_id, variable, info_to_keep) %>% 
  pivot_wider(names_from = variable, values_from = info_to_keep) %>% 
  mutate(response_id = "correct") 

```

```{r}
# Check data: keep one row per participant with the correct responses

checked_LEQ <- LEQ_wide_double_data %>% 
  # Remove babies from LimeSurvey
  filter(!c(study_id == "S016" | 
           study_id == "S026" | 
           study_id == "S028" | 
           study_id == "S041" | 
           study_id == "S057")) %>% 
  arrange(study_id, recorded_date) %>% 
  group_by(study_id) %>% 
  # Keep the rows with all the correct situations (some entries do not have all the situations)
  filter(sit_count == max(sit_count)) %>%  
  # Keep only one row per baby
  filter(recorded_date == max(recorded_date)) %>%  
  # Turn everything into character to join with discrepancies dataframe
  mutate(across(everything(), as.character)) %>% 
  # Join with discrepancies data
  full_join(LEQ_wide_discrepancies) %>% 
  arrange(study_id, response_id) %>% 
  # Fill the discrepancy rows with the responses that were not discrepant
  group_by(study_id) %>% 
  fill(c(recorded_date:l4_overall_exp), .direction = "up") %>% 
  # Crete column with 1 as the row to keep (and 2 to be removed) as the first row per baby is either "correct" (with the checked discrepancies) or the only row (because there were no discrepancies)
  mutate(response_correct = row_number()) %>% 
  relocate(response_correct, .after = response_id) %>% 
  mutate(response_id = case_when(response_id == "correct" ~ lead(response_id),
                                 TRUE ~ response_id)) %>% 
  filter(response_correct == 1)

```

```{r}
# Code originally written by Hilary Killam (script to clean Qualtrics LEQ output)
# Function for swapping elements in a string for later efficient renaming
str_swap <- function(string, str1, str2) {
  if (str_detect(string, str1, negate = TRUE) | str_detect(string, str2, negate = TRUE)) {
    stop("str1 and str2 (the two pieces to be swapped) must both appear in the full string")
  }
  str1 <- as.character(str1)
  str2 <- as.character(str2)
  str1pos <- str_locate(string, str1)
  str2pos <- str_locate(string, str2)
  
  if (str1pos[1] > str2pos[1]) {
    str1temp <- str1
    str1 <- str2
    str2 <- str1temp
    str1pos <- str_locate(string, str1)
    str2pos <- str_locate(string, str2)
  }
  string <- paste0(str_sub(string, 1L, str1pos[1]-1), str2, str_sub(string, str1pos[2]+1, str2pos[1]-1), str1, str_sub(string, str2pos[2]+1, str_length(string)))
  return(string)
}

#vectorize the function so it works across multiple inputs
str_swap <- Vectorize(str_swap)
```


```{r}
# Convert dataframe to long format
# Code originally written by Hilary Killam (script to clean Qualtrics LEQ output), modified to work with checked dataset

checked_long_LEQ <- checked_LEQ %>% 
  rename(num_sits = sit_count,
         l1.lang_name = child_l1,
         l2.lang_name = child_l2,
         l3.lang_name = child_l3,
         l4.lang_name = child_l4,
         l1.glob_est = glob_est_l1,
         l2.glob_est = glob_est_l2,
         l3.glob_est = glob_est_l3,
         l4.glob_est = glob_est_l4) %>%
  select(-response_correct, -ends_with("mon"), -ends_with("tue"), -ends_with("wed"), -ends_with("thu"), -ends_with("fri"), -ends_with("sat"), -ends_with("sun"), -contains("cgvr"), -contains("daycare"), -contains("trips")) %>% 
  rename_with(~ str_swap(string = .x, 
                         str1 = str_extract(.x, "^l\\d_"), 
                         str2 = str_extract(.x, "sit\\d+_")), 
              matches("l\\d_sit\\d+")) %>%
  rename_with(~ str_replace(.x, "(?<=l\\d)_", ".")) %>% 
  pivot_longer(starts_with("sit"), 
               names_to = c('situation', '.value'),
               names_pattern = '(.*)_(.+)') %>% 
  filter(!is.na(situation)) %>% 
  group_by(response_id) %>%
  mutate(start = case_when(start == 0 ~ start,
                           TRUE ~ lag(end))) %>%
  ungroup() %>%
  filter(parse_number(situation) <= as.numeric(num_sits)) %>%

  pivot_longer(matches("^l\\d."),
               names_to = c('language', '.value'),
               names_pattern = '(.*)\\.(.+)')  %>%
  filter(!is.na(lang_name))  %>% 
  # Make numeric columns numeric again
  mutate(across(glob_est:hrsperweek, as.numeric)) %>%
  # Fix exposure variables, which in Qualtrics is only based on most recent situation (not all of them, but when data is long, this makes no sense)
  group_by(response_id, situation) %>%
  mutate(curr_exp = round(hrsperweek/sum(hrsperweek), 3),
         sit_hrs = sum(hrsperweek)) %>%
  group_by(response_id, language) %>%
  mutate(cumu_hrs = cumsum(hrsperweek)) %>%
  group_by(response_id) %>%
  mutate(cumu_exp = round(cumu_hrs/(sit_hrs*parse_number(situation)), 3)) %>%
  select(-sit_hrs) %>%
  group_by(response_id) %>%
  mutate(num_langs = n_distinct(lang_name),
         situation = parse_number(situation),
         glob_est = glob_est/100,
         overall_exp = overall_exp/100,
         lang_temp = case_when(language == "l3" | language == "l4" ~ "other",
                               TRUE ~ language)) %>%
  # Flag kids who have multilingual situations where l3 + l4 > 10%
  group_by(response_id, situation, lang_temp) %>%
  mutate(multilingual = case_when(sum(cumu_exp) > .1 & lang_temp == "other" ~ 1,
                                  TRUE ~ 0)) %>%
  group_by(response_id, situation) %>%
  mutate(multilingual = sum(multilingual)) %>%
  select(-lang_temp) %>%
  group_by(response_id, language) %>%
  # Flag kids who have situations where exposure changes more than 20% from previous
  mutate(large_change = case_when(lag(cumu_exp) > cumu_exp + .2 | lag(cumu_exp) < cumu_exp - .2 ~ 1,
                                  TRUE ~ 0)) %>%
  ungroup() %>% 
  # Remove rows of empty phases
  filter(!(is.na(start)))

```

```{r}
# Save dataframe as csv file
write_csv(checked_long_LEQ, 'data/00_Qualtrics_LEQ_checked_long.csv')
```

